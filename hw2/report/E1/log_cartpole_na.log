########################
logging outputs to  /root/CS285_homework/hw2/cs285/scripts/../../data/q2_pg_cartpole_na_CartPole-v0_27-05-2024_14-51-32
########################
Using GPU id 0
MLPPolicy.__init__ 4 2

********** Iteration 0 ************

Collecting data for eval...
Eval_AverageReturn : 35.0
Eval_StdReturn : 18.193405151367188
Eval_MaxReturn : 76.0
Eval_MinReturn : 13.0
Eval_AverageEpLen : 35.0
Train_AverageReturn : 23.395349502563477
Train_StdReturn : 17.227802276611328
Train_MaxReturn : 78.0
Train_MinReturn : 9.0
Train_AverageEpLen : 23.3953488372093
Actor Loss : -0.007192058954387903
Train_EnvstepsSoFar : 1006
TimeSinceStart : 1.1577486991882324
Initial_DataCollection_AverageReturn : 23.395349502563477
Done logging...



********** Iteration 1 ************

Collecting data for eval...
Eval_AverageReturn : 31.30769157409668
Eval_StdReturn : 12.072757720947266
Eval_MaxReturn : 52.0
Eval_MinReturn : 13.0
Eval_AverageEpLen : 31.307692307692307
Train_AverageReturn : 29.342857360839844
Train_StdReturn : 15.15810489654541
Train_MaxReturn : 77.0
Train_MinReturn : 11.0
Train_AverageEpLen : 29.34285714285714
Actor Loss : -0.002653235336765647
Train_EnvstepsSoFar : 2033
TimeSinceStart : 2.1310629844665527
Done logging...



********** Iteration 2 ************

Collecting data for eval...
Eval_AverageReturn : 57.75
Eval_StdReturn : 18.267114639282227
Eval_MaxReturn : 80.0
Eval_MinReturn : 21.0
Eval_AverageEpLen : 57.75
Train_AverageReturn : 36.5
Train_StdReturn : 24.805673599243164
Train_MaxReturn : 142.0
Train_MinReturn : 16.0
Train_AverageEpLen : 36.5
Actor Loss : -0.009716413915157318
Train_EnvstepsSoFar : 3055
TimeSinceStart : 3.131528377532959
Done logging...



********** Iteration 3 ************

Collecting data for eval...
Eval_AverageReturn : 56.0
Eval_StdReturn : 21.100948333740234
Eval_MaxReturn : 79.0
Eval_MinReturn : 18.0
Eval_AverageEpLen : 56.0
Train_AverageReturn : 61.29411697387695
Train_StdReturn : 30.94542694091797
Train_MaxReturn : 164.0
Train_MinReturn : 21.0
Train_AverageEpLen : 61.294117647058826
Actor Loss : 0.00551762105897069
Train_EnvstepsSoFar : 4097
TimeSinceStart : 4.139594316482544
Done logging...



********** Iteration 4 ************

Collecting data for eval...
Eval_AverageReturn : 67.42857360839844
Eval_StdReturn : 44.94713592529297
Eval_MaxReturn : 164.0
Eval_MinReturn : 19.0
Eval_AverageEpLen : 67.42857142857143
Train_AverageReturn : 55.21052551269531
Train_StdReturn : 21.891067504882812
Train_MaxReturn : 101.0
Train_MinReturn : 24.0
Train_AverageEpLen : 55.21052631578947
Actor Loss : -0.0002996439579874277
Train_EnvstepsSoFar : 5146
TimeSinceStart : 5.175350904464722
Done logging...



********** Iteration 5 ************

Collecting data for eval...
Eval_AverageReturn : 44.599998474121094
Eval_StdReturn : 11.968292236328125
Eval_MaxReturn : 59.0
Eval_MinReturn : 24.0
Eval_AverageEpLen : 44.6
Train_AverageReturn : 55.78947448730469
Train_StdReturn : 34.136844635009766
Train_MaxReturn : 137.0
Train_MinReturn : 14.0
Train_AverageEpLen : 55.78947368421053
Actor Loss : -0.0003624884702730924
Train_EnvstepsSoFar : 6206
TimeSinceStart : 6.202359437942505
Done logging...



********** Iteration 6 ************

Collecting data for eval...
Eval_AverageReturn : 58.57143020629883
Eval_StdReturn : 46.52451705932617
Eval_MaxReturn : 172.0
Eval_MinReturn : 33.0
Eval_AverageEpLen : 58.57142857142857
Train_AverageReturn : 51.33333206176758
Train_StdReturn : 34.259979248046875
Train_MaxReturn : 150.0
Train_MinReturn : 21.0
Train_AverageEpLen : 51.333333333333336
Actor Loss : 0.0072582862339913845
Train_EnvstepsSoFar : 7284
TimeSinceStart : 7.201739311218262
Done logging...



********** Iteration 7 ************

Collecting data for eval...
Eval_AverageReturn : 77.5
Eval_StdReturn : 39.86957931518555
Eval_MaxReturn : 119.0
Eval_MinReturn : 23.0
Eval_AverageEpLen : 77.5
Train_AverageReturn : 57.47368240356445
Train_StdReturn : 24.69683074951172
Train_MaxReturn : 113.0
Train_MinReturn : 23.0
Train_AverageEpLen : 57.473684210526315
Actor Loss : 0.0005493397475220263
Train_EnvstepsSoFar : 8376
TimeSinceStart : 8.249362468719482
Done logging...



********** Iteration 8 ************

Collecting data for eval...
Eval_AverageReturn : 69.0
Eval_StdReturn : 22.472204208374023
Eval_MaxReturn : 111.0
Eval_MinReturn : 44.0
Eval_AverageEpLen : 69.0
Train_AverageReturn : 92.36363983154297
Train_StdReturn : 22.325170516967773
Train_MaxReturn : 121.0
Train_MinReturn : 56.0
Train_AverageEpLen : 92.36363636363636
Actor Loss : -0.003518888261169195
Train_EnvstepsSoFar : 9392
TimeSinceStart : 9.213718175888062
Done logging...



********** Iteration 9 ************

Collecting data for eval...
Eval_AverageReturn : 107.5999984741211
Eval_StdReturn : 47.659629821777344
Eval_MaxReturn : 172.0
Eval_MinReturn : 62.0
Eval_AverageEpLen : 107.6
Train_AverageReturn : 75.64286041259766
Train_StdReturn : 30.92989158630371
Train_MaxReturn : 133.0
Train_MinReturn : 36.0
Train_AverageEpLen : 75.64285714285714
Actor Loss : -0.004997825250029564
Train_EnvstepsSoFar : 10451
TimeSinceStart : 10.285919427871704
Done logging...



********** Iteration 10 ************

Collecting data for eval...
Eval_AverageReturn : 91.5999984741211
Eval_StdReturn : 31.740196228027344
Eval_MaxReturn : 134.0
Eval_MinReturn : 50.0
Eval_AverageEpLen : 91.6
Train_AverageReturn : 86.07691955566406
Train_StdReturn : 32.58707046508789
Train_MaxReturn : 141.0
Train_MinReturn : 36.0
Train_AverageEpLen : 86.07692307692308
Actor Loss : 0.00232397997751832
Train_EnvstepsSoFar : 11570
TimeSinceStart : 11.347967624664307
Done logging...



********** Iteration 11 ************

Collecting data for eval...
Eval_AverageReturn : 135.0
Eval_StdReturn : 35.44009017944336
Eval_MaxReturn : 185.0
Eval_MinReturn : 107.0
Eval_AverageEpLen : 135.0
Train_AverageReturn : 100.90908813476562
Train_StdReturn : 41.148193359375
Train_MaxReturn : 189.0
Train_MinReturn : 39.0
Train_AverageEpLen : 100.9090909090909
Actor Loss : 0.0020030296873301268
Train_EnvstepsSoFar : 12680
TimeSinceStart : 12.368683099746704
Done logging...



********** Iteration 12 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 100.0999984741211
Train_StdReturn : 48.933528900146484
Train_MaxReturn : 200.0
Train_MinReturn : 41.0
Train_AverageEpLen : 100.1
Actor Loss : -0.022157002240419388
Train_EnvstepsSoFar : 13681
TimeSinceStart : 13.310566663742065
Done logging...



********** Iteration 13 ************

Collecting data for eval...
Eval_AverageReturn : 147.3333282470703
Eval_StdReturn : 10.077478408813477
Eval_MaxReturn : 161.0
Eval_MinReturn : 137.0
Eval_AverageEpLen : 147.33333333333334
Train_AverageReturn : 128.875
Train_StdReturn : 38.40389633178711
Train_MaxReturn : 192.0
Train_MinReturn : 64.0
Train_AverageEpLen : 128.875
Actor Loss : -0.004552636761218309
Train_EnvstepsSoFar : 14712
TimeSinceStart : 14.300773620605469
Done logging...



********** Iteration 14 ************

Collecting data for eval...
Eval_AverageReturn : 142.0
Eval_StdReturn : 69.68500518798828
Eval_MaxReturn : 200.0
Eval_MinReturn : 44.0
Eval_AverageEpLen : 142.0
Train_AverageReturn : 167.5
Train_StdReturn : 26.769073486328125
Train_MaxReturn : 200.0
Train_MinReturn : 134.0
Train_AverageEpLen : 167.5
Actor Loss : -0.004931445233523846
Train_EnvstepsSoFar : 15717
TimeSinceStart : 15.269957780838013
Done logging...



********** Iteration 15 ************

Collecting data for eval...
Eval_AverageReturn : 168.6666717529297
Eval_StdReturn : 34.883934020996094
Eval_MaxReturn : 200.0
Eval_MinReturn : 120.0
Eval_AverageEpLen : 168.66666666666666
Train_AverageReturn : 160.57142639160156
Train_StdReturn : 22.115652084350586
Train_MaxReturn : 200.0
Train_MinReturn : 135.0
Train_AverageEpLen : 160.57142857142858
Actor Loss : -0.012432537972927094
Train_EnvstepsSoFar : 16841
TimeSinceStart : 16.3658549785614
Done logging...



********** Iteration 16 ************

Collecting data for eval...
Eval_AverageReturn : 186.0
Eval_StdReturn : 19.79899024963379
Eval_MaxReturn : 200.0
Eval_MinReturn : 158.0
Eval_AverageEpLen : 186.0
Train_AverageReturn : 125.5
Train_StdReturn : 48.86716842651367
Train_MaxReturn : 200.0
Train_MinReturn : 27.0
Train_AverageEpLen : 125.5
Actor Loss : -0.022107750177383423
Train_EnvstepsSoFar : 17845
TimeSinceStart : 17.4137122631073
Done logging...



********** Iteration 17 ************

Collecting data for eval...
Eval_AverageReturn : 146.6666717529297
Eval_StdReturn : 39.9110107421875
Eval_MaxReturn : 200.0
Eval_MinReturn : 104.0
Eval_AverageEpLen : 146.66666666666666
Train_AverageReturn : 145.7142791748047
Train_StdReturn : 28.29292869567871
Train_MaxReturn : 200.0
Train_MinReturn : 102.0
Train_AverageEpLen : 145.71428571428572
Actor Loss : -0.01296510361135006
Train_EnvstepsSoFar : 18865
TimeSinceStart : 18.395303964614868
Done logging...



********** Iteration 18 ************

Collecting data for eval...
Eval_AverageReturn : 170.0
Eval_StdReturn : 24.055492401123047
Eval_MaxReturn : 196.0
Eval_MinReturn : 138.0
Eval_AverageEpLen : 170.0
Train_AverageReturn : 181.1666717529297
Train_StdReturn : 28.286725997924805
Train_MaxReturn : 200.0
Train_MinReturn : 127.0
Train_AverageEpLen : 181.16666666666666
Actor Loss : -0.005825705826282501
Train_EnvstepsSoFar : 19952
TimeSinceStart : 19.46988534927368
Done logging...



********** Iteration 19 ************

Collecting data for eval...
Eval_AverageReturn : 176.0
Eval_StdReturn : 33.941123962402344
Eval_MaxReturn : 200.0
Eval_MinReturn : 128.0
Eval_AverageEpLen : 176.0
Train_AverageReturn : 185.1666717529297
Train_StdReturn : 22.003156661987305
Train_MaxReturn : 200.0
Train_MinReturn : 144.0
Train_AverageEpLen : 185.16666666666666
Actor Loss : -0.007123752497136593
Train_EnvstepsSoFar : 21063
TimeSinceStart : 20.57809591293335
Done logging...



********** Iteration 20 ************

Collecting data for eval...
Eval_AverageReturn : 188.6666717529297
Eval_StdReturn : 15.326086044311523
Eval_MaxReturn : 200.0
Eval_MinReturn : 167.0
Eval_AverageEpLen : 188.66666666666666
Train_AverageReturn : 198.0
Train_StdReturn : 2.886751174926758
Train_MaxReturn : 200.0
Train_MinReturn : 193.0
Train_AverageEpLen : 198.0
Actor Loss : -0.0007707352051511407
Train_EnvstepsSoFar : 22251
TimeSinceStart : 21.766775131225586
Done logging...



********** Iteration 21 ************

Collecting data for eval...
Eval_AverageReturn : 180.0
Eval_StdReturn : 16.329931259155273
Eval_MaxReturn : 200.0
Eval_MinReturn : 160.0
Eval_AverageEpLen : 180.0
Train_AverageReturn : 197.3333282470703
Train_StdReturn : 5.96284818649292
Train_MaxReturn : 200.0
Train_MinReturn : 184.0
Train_AverageEpLen : 197.33333333333334
Actor Loss : -0.014686569571495056
Train_EnvstepsSoFar : 23435
TimeSinceStart : 22.924859046936035
Done logging...



********** Iteration 22 ************

Collecting data for eval...
Eval_AverageReturn : 175.0
Eval_StdReturn : 32.56787872314453
Eval_MaxReturn : 200.0
Eval_MinReturn : 129.0
Eval_AverageEpLen : 175.0
Train_AverageReturn : 174.1666717529297
Train_StdReturn : 38.4118766784668
Train_MaxReturn : 200.0
Train_MinReturn : 94.0
Train_AverageEpLen : 174.16666666666666
Actor Loss : -0.006107538007199764
Train_EnvstepsSoFar : 24480
TimeSinceStart : 23.979955673217773
Done logging...



********** Iteration 23 ************

Collecting data for eval...
Eval_AverageReturn : 188.6666717529297
Eval_StdReturn : 16.027753829956055
Eval_MaxReturn : 200.0
Eval_MinReturn : 166.0
Eval_AverageEpLen : 188.66666666666666
Train_AverageReturn : 167.5
Train_StdReturn : 38.943336486816406
Train_MaxReturn : 200.0
Train_MinReturn : 94.0
Train_AverageEpLen : 167.5
Actor Loss : 0.009247422218322754
Train_EnvstepsSoFar : 25485
TimeSinceStart : 25.040510177612305
Done logging...



********** Iteration 24 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 183.1666717529297
Train_StdReturn : 37.640480041503906
Train_MaxReturn : 200.0
Train_MinReturn : 99.0
Train_AverageEpLen : 183.16666666666666
Actor Loss : -0.01162760891020298
Train_EnvstepsSoFar : 26584
TimeSinceStart : 26.044808387756348
Done logging...



********** Iteration 25 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 199.6666717529297
Train_StdReturn : 0.745356023311615
Train_MaxReturn : 200.0
Train_MinReturn : 198.0
Train_AverageEpLen : 199.66666666666666
Actor Loss : 0.0012570824474096298
Train_EnvstepsSoFar : 27782
TimeSinceStart : 27.118512630462646
Done logging...



********** Iteration 26 ************
[INFO]: loss is NAN

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
Train_EnvstepsSoFar : 28782
TimeSinceStart : 28.058045625686646
Done logging...



********** Iteration 27 ************
[INFO]: loss is NAN

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
Train_EnvstepsSoFar : 29782
TimeSinceStart : 28.998518466949463
Done logging...



********** Iteration 28 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 192.8333282470703
Train_StdReturn : 16.02515411376953
Train_MaxReturn : 200.0
Train_MinReturn : 157.0
Train_AverageEpLen : 192.83333333333334
Actor Loss : -0.008094271644949913
Train_EnvstepsSoFar : 30939
TimeSinceStart : 30.050724029541016
Done logging...



********** Iteration 29 ************
[INFO]: loss is NAN

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
Train_EnvstepsSoFar : 31939
TimeSinceStart : 30.993512630462646
Done logging...



********** Iteration 30 ************
[INFO]: loss is NAN

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
Train_EnvstepsSoFar : 32939
TimeSinceStart : 31.932636260986328
Done logging...



********** Iteration 31 ************
[INFO]: loss is NAN

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
Train_EnvstepsSoFar : 33939
TimeSinceStart : 32.873945236206055
Done logging...



********** Iteration 32 ************
[INFO]: loss is NAN

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
Train_EnvstepsSoFar : 34939
TimeSinceStart : 33.819129943847656
Done logging...



********** Iteration 33 ************
[INFO]: loss is NAN

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
Train_EnvstepsSoFar : 35939
TimeSinceStart : 34.76064419746399
Done logging...



********** Iteration 34 ************
[INFO]: loss is NAN

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
Train_EnvstepsSoFar : 36939
TimeSinceStart : 35.708377838134766
Done logging...



********** Iteration 35 ************
[INFO]: loss is NAN

Collecting data for eval...
Eval_AverageReturn : 195.6666717529297
Eval_StdReturn : 6.12825870513916
Eval_MaxReturn : 200.0
Eval_MinReturn : 187.0
Eval_AverageEpLen : 195.66666666666666
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
Train_EnvstepsSoFar : 37939
TimeSinceStart : 36.77355670928955
Done logging...



********** Iteration 36 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 195.8333282470703
Train_StdReturn : 9.316949844360352
Train_MaxReturn : 200.0
Train_MinReturn : 175.0
Train_AverageEpLen : 195.83333333333334
Actor Loss : -0.0007100710063241422
Train_EnvstepsSoFar : 39114
TimeSinceStart : 37.83607769012451
Done logging...



********** Iteration 37 ************
[INFO]: loss is NAN

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
Train_EnvstepsSoFar : 40114
TimeSinceStart : 38.775901794433594
Done logging...



********** Iteration 38 ************
[INFO]: loss is NAN

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
Train_EnvstepsSoFar : 41114
TimeSinceStart : 39.71543049812317
Done logging...



********** Iteration 39 ************
[INFO]: loss is NAN

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
Train_EnvstepsSoFar : 42114
TimeSinceStart : 40.65439224243164
Done logging...



********** Iteration 40 ************
[INFO]: loss is NAN

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
Train_EnvstepsSoFar : 43114
TimeSinceStart : 41.59335994720459
Done logging...



********** Iteration 41 ************
[INFO]: loss is NAN

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
Train_EnvstepsSoFar : 44114
TimeSinceStart : 42.53211855888367
Done logging...



********** Iteration 42 ************
[INFO]: loss is NAN

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
Train_EnvstepsSoFar : 45114
TimeSinceStart : 43.47244691848755
Done logging...



********** Iteration 43 ************
[INFO]: loss is NAN

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
Train_EnvstepsSoFar : 46114
TimeSinceStart : 44.41231679916382
Done logging...



********** Iteration 44 ************
[INFO]: loss is NAN

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
Train_EnvstepsSoFar : 47114
TimeSinceStart : 45.372546911239624
Done logging...



********** Iteration 45 ************
[INFO]: loss is NAN

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
Train_EnvstepsSoFar : 48114
TimeSinceStart : 46.31156086921692
Done logging...



********** Iteration 46 ************
[INFO]: loss is NAN

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
Train_EnvstepsSoFar : 49114
TimeSinceStart : 47.25146412849426
Done logging...



********** Iteration 47 ************
[INFO]: loss is NAN

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
Train_EnvstepsSoFar : 50114
TimeSinceStart : 48.19077706336975
Done logging...



********** Iteration 48 ************
[INFO]: loss is NAN

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
Train_EnvstepsSoFar : 51114
TimeSinceStart : 49.13055062294006
Done logging...



********** Iteration 49 ************
[INFO]: loss is NAN

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
Train_EnvstepsSoFar : 52114
TimeSinceStart : 50.069963216781616
Done logging...



********** Iteration 50 ************
[INFO]: loss is NAN

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
Train_EnvstepsSoFar : 53114
TimeSinceStart : 51.00923156738281
Done logging...



********** Iteration 51 ************
[INFO]: loss is NAN

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
Train_EnvstepsSoFar : 54114
TimeSinceStart : 51.948097467422485
Done logging...



********** Iteration 52 ************
[INFO]: loss is NAN

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
Train_EnvstepsSoFar : 55114
TimeSinceStart : 52.886287450790405
Done logging...



********** Iteration 53 ************
[INFO]: loss is NAN

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
Train_EnvstepsSoFar : 56114
TimeSinceStart : 53.8259003162384
Done logging...



********** Iteration 54 ************
[INFO]: loss is NAN

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
Train_EnvstepsSoFar : 57114
TimeSinceStart : 54.77153658866882
Done logging...



********** Iteration 55 ************
[INFO]: loss is NAN

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
Train_EnvstepsSoFar : 58114
TimeSinceStart : 55.70789909362793
Done logging...



********** Iteration 56 ************
[INFO]: loss is NAN

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
Train_EnvstepsSoFar : 59114
TimeSinceStart : 56.63262748718262
Done logging...



********** Iteration 57 ************
[INFO]: loss is NAN

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
Train_EnvstepsSoFar : 60114
TimeSinceStart : 57.55726647377014
Done logging...



********** Iteration 58 ************
[INFO]: loss is NAN

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
Train_EnvstepsSoFar : 61114
TimeSinceStart : 58.48484468460083
Done logging...



********** Iteration 59 ************
[INFO]: loss is NAN

Collecting data for eval...
Eval_AverageReturn : 199.6666717529297
Eval_StdReturn : 0.471404492855072
Eval_MaxReturn : 200.0
Eval_MinReturn : 199.0
Eval_AverageEpLen : 199.66666666666666
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
Train_EnvstepsSoFar : 62114
TimeSinceStart : 59.54005002975464
Done logging...



********** Iteration 60 ************
[INFO]: loss is NAN

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
Train_EnvstepsSoFar : 63114
TimeSinceStart : 60.461915016174316
Done logging...



********** Iteration 61 ************
[INFO]: loss is NAN

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
Train_EnvstepsSoFar : 64114
TimeSinceStart : 61.385303258895874
Done logging...



********** Iteration 62 ************
[INFO]: loss is NAN

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
Train_EnvstepsSoFar : 65114
TimeSinceStart : 62.309773445129395
Done logging...



********** Iteration 63 ************
[INFO]: loss is NAN

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
Train_EnvstepsSoFar : 66114
TimeSinceStart : 63.23264145851135
Done logging...



********** Iteration 64 ************
[INFO]: loss is NAN

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
Train_EnvstepsSoFar : 67114
TimeSinceStart : 64.15484142303467
Done logging...



********** Iteration 65 ************
[INFO]: loss is NAN

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
Train_EnvstepsSoFar : 68114
TimeSinceStart : 65.08773756027222
Done logging...



********** Iteration 66 ************
[INFO]: loss is NAN

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
Train_EnvstepsSoFar : 69114
TimeSinceStart : 66.00831913948059
Done logging...



********** Iteration 67 ************
[INFO]: loss is NAN

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
Train_EnvstepsSoFar : 70114
TimeSinceStart : 66.93160700798035
Done logging...



********** Iteration 68 ************
[INFO]: loss is NAN

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
Train_EnvstepsSoFar : 71114
TimeSinceStart : 67.85265302658081
Done logging...



********** Iteration 69 ************
[INFO]: loss is NAN

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
Train_EnvstepsSoFar : 72114
TimeSinceStart : 68.77567267417908
Done logging...



********** Iteration 70 ************
[INFO]: loss is NAN

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
Train_EnvstepsSoFar : 73114
TimeSinceStart : 69.69844341278076
Done logging...



********** Iteration 71 ************
[INFO]: loss is NAN

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
Train_EnvstepsSoFar : 74114
TimeSinceStart : 70.62127542495728
Done logging...



********** Iteration 72 ************
[INFO]: loss is NAN

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
Train_EnvstepsSoFar : 75114
TimeSinceStart : 71.54387950897217
Done logging...



********** Iteration 73 ************
[INFO]: loss is NAN

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
Train_EnvstepsSoFar : 76114
TimeSinceStart : 72.46648573875427
Done logging...



********** Iteration 74 ************
[INFO]: loss is NAN

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
Train_EnvstepsSoFar : 77114
TimeSinceStart : 73.38889408111572
Done logging...



********** Iteration 75 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 182.8333282470703
Train_StdReturn : 38.385833740234375
Train_MaxReturn : 200.0
Train_MinReturn : 97.0
Train_AverageEpLen : 182.83333333333334
Actor Loss : -0.033697545528411865
Train_EnvstepsSoFar : 78211
TimeSinceStart : 74.37807106971741
Done logging...



********** Iteration 76 ************
[INFO]: loss is NAN

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
Train_EnvstepsSoFar : 79211
TimeSinceStart : 75.31559872627258
Done logging...



********** Iteration 77 ************
[INFO]: loss is NAN

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
Train_EnvstepsSoFar : 80211
TimeSinceStart : 76.23624086380005
Done logging...



********** Iteration 78 ************
[INFO]: loss is NAN

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
Train_EnvstepsSoFar : 81211
TimeSinceStart : 77.15884137153625
Done logging...



********** Iteration 79 ************
[INFO]: loss is NAN

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
Train_EnvstepsSoFar : 82211
TimeSinceStart : 78.08221912384033
Done logging...



********** Iteration 80 ************
[INFO]: loss is NAN

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
Train_EnvstepsSoFar : 83211
TimeSinceStart : 79.01210951805115
Done logging...



********** Iteration 81 ************
[INFO]: loss is NAN

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
Train_EnvstepsSoFar : 84211
TimeSinceStart : 79.93379807472229
Done logging...



********** Iteration 82 ************
[INFO]: loss is NAN

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
Train_EnvstepsSoFar : 85211
TimeSinceStart : 80.85700988769531
Done logging...



********** Iteration 83 ************
[INFO]: loss is NAN

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
Train_EnvstepsSoFar : 86211
TimeSinceStart : 81.77942204475403
Done logging...



********** Iteration 84 ************
[INFO]: loss is NAN

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
Train_EnvstepsSoFar : 87211
TimeSinceStart : 82.70153379440308
Done logging...



********** Iteration 85 ************
[INFO]: loss is NAN

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
Train_EnvstepsSoFar : 88211
TimeSinceStart : 83.62309527397156
Done logging...



********** Iteration 86 ************
[INFO]: loss is NAN

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
Train_EnvstepsSoFar : 89211
TimeSinceStart : 84.54616665840149
Done logging...



********** Iteration 87 ************
[INFO]: loss is NAN

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
Train_EnvstepsSoFar : 90211
TimeSinceStart : 85.47896099090576
Done logging...



********** Iteration 88 ************
[INFO]: loss is NAN

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
Train_EnvstepsSoFar : 91211
TimeSinceStart : 86.40078353881836
Done logging...



********** Iteration 89 ************
[INFO]: loss is NAN

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
Train_EnvstepsSoFar : 92211
TimeSinceStart : 87.32185769081116
Done logging...



********** Iteration 90 ************
[INFO]: loss is NAN

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
Train_EnvstepsSoFar : 93211
TimeSinceStart : 88.24317765235901
Done logging...



********** Iteration 91 ************
[INFO]: loss is NAN

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
Train_EnvstepsSoFar : 94211
TimeSinceStart : 89.16478824615479
Done logging...



********** Iteration 92 ************
[INFO]: loss is NAN

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
Train_EnvstepsSoFar : 95211
TimeSinceStart : 90.0892903804779
Done logging...



********** Iteration 93 ************
[INFO]: loss is NAN

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
Train_EnvstepsSoFar : 96211
TimeSinceStart : 91.01575946807861
Done logging...



********** Iteration 94 ************
[INFO]: loss is NAN

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
Train_EnvstepsSoFar : 97211
TimeSinceStart : 91.9386293888092
Done logging...



********** Iteration 95 ************
[INFO]: loss is NAN

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
Train_EnvstepsSoFar : 98211
TimeSinceStart : 92.86002731323242
Done logging...



********** Iteration 96 ************
[INFO]: loss is NAN

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
Train_EnvstepsSoFar : 99211
TimeSinceStart : 93.7839903831482
Done logging...



********** Iteration 97 ************
[INFO]: loss is NAN

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
Train_EnvstepsSoFar : 100211
TimeSinceStart : 94.70560622215271
Done logging...



********** Iteration 98 ************
[INFO]: loss is NAN

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
Train_EnvstepsSoFar : 101211
TimeSinceStart : 95.64048957824707
Done logging...



********** Iteration 99 ************
[INFO]: loss is NAN

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
Train_EnvstepsSoFar : 102211
TimeSinceStart : 96.56110835075378
Done logging...


