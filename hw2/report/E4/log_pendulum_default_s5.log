########################
logging outputs to  /home/zhh/MyFile/OnlineCourses/Berkeley285/homework_repo/hw2/cs285/scripts/../../data/q2_pg_pendulum_default_s5_InvertedPendulum-v4_27-05-2024_22-40-01
########################
Using CPU.
MLPPolicy.__init__ 4 1

********** Iteration 0 ************

Collecting data for eval...
Eval_AverageReturn : 12.29411792755127
Eval_StdReturn : 5.823529243469238
Eval_MaxReturn : 24.0
Eval_MinReturn : 4.0
Eval_AverageEpLen : 12.294117647058824
Train_AverageReturn : 8.622413635253906
Train_StdReturn : 4.586394786834717
Train_MaxReturn : 32.0
Train_MinReturn : 3.0
Train_AverageEpLen : 8.622413793103448
Actor Loss : -272.92242431640625
Baseline Loss : 48.97321701049805
Train_EnvstepsSoFar : 5001
TimeSinceStart : 0.5774831771850586
Initial_DataCollection_AverageReturn : 8.622413635253906
Done logging...



********** Iteration 1 ************

Collecting data for eval...
Eval_AverageReturn : 15.629630088806152
Eval_StdReturn : 7.597017765045166
Eval_MaxReturn : 41.0
Eval_MinReturn : 6.0
Eval_AverageEpLen : 15.62962962962963
Train_AverageReturn : 10.439583778381348
Train_StdReturn : 6.41389274597168
Train_MaxReturn : 53.0
Train_MinReturn : 3.0
Train_AverageEpLen : 10.439583333333333
Actor Loss : -138.60049438476562
Baseline Loss : 68.09024963378906
Train_EnvstepsSoFar : 10012
TimeSinceStart : 1.1355412006378174
Done logging...



********** Iteration 2 ************

Collecting data for eval...
Eval_AverageReturn : 19.090909957885742
Eval_StdReturn : 9.375543594360352
Eval_MaxReturn : 46.0
Eval_MinReturn : 5.0
Eval_AverageEpLen : 19.09090909090909
Train_AverageReturn : 14.543604850769043
Train_StdReturn : 9.245574951171875
Train_MaxReturn : 57.0
Train_MinReturn : 3.0
Train_AverageEpLen : 14.543604651162791
Actor Loss : -228.60621643066406
Baseline Loss : 109.94526672363281
Train_EnvstepsSoFar : 15015
TimeSinceStart : 1.6789195537567139
Done logging...



********** Iteration 3 ************

Collecting data for eval...
Eval_AverageReturn : 34.0
Eval_StdReturn : 16.20185089111328
Eval_MaxReturn : 68.0
Eval_MinReturn : 13.0
Eval_AverageEpLen : 34.0
Train_AverageReturn : 20.189516067504883
Train_StdReturn : 12.1950044631958
Train_MaxReturn : 68.0
Train_MinReturn : 3.0
Train_AverageEpLen : 20.18951612903226
Actor Loss : -207.20697021484375
Baseline Loss : 168.91908264160156
Train_EnvstepsSoFar : 20022
TimeSinceStart : 2.2251365184783936
Done logging...



********** Iteration 4 ************

Collecting data for eval...
Eval_AverageReturn : 26.294116973876953
Eval_StdReturn : 14.799700736999512
Eval_MaxReturn : 56.0
Eval_MinReturn : 5.0
Eval_AverageEpLen : 26.294117647058822
Train_AverageReturn : 25.53061294555664
Train_StdReturn : 13.315791130065918
Train_MaxReturn : 67.0
Train_MinReturn : 5.0
Train_AverageEpLen : 25.53061224489796
Actor Loss : -133.50277709960938
Baseline Loss : 200.6438781738281
Train_EnvstepsSoFar : 25026
TimeSinceStart : 2.73803448677063
Done logging...



********** Iteration 5 ************

Collecting data for eval...
Eval_AverageReturn : 28.133333206176758
Eval_StdReturn : 13.519698143005371
Eval_MaxReturn : 53.0
Eval_MinReturn : 6.0
Eval_AverageEpLen : 28.133333333333333
Train_AverageReturn : 31.465408325195312
Train_StdReturn : 16.619220733642578
Train_MaxReturn : 114.0
Train_MinReturn : 7.0
Train_AverageEpLen : 31.465408805031448
Actor Loss : -102.92060852050781
Baseline Loss : 346.0493591308594
Train_EnvstepsSoFar : 30029
TimeSinceStart : 3.235400438308716
Done logging...



********** Iteration 6 ************

Collecting data for eval...
Eval_AverageReturn : 53.5
Eval_StdReturn : 19.07223129272461
Eval_MaxReturn : 80.0
Eval_MinReturn : 25.0
Eval_AverageEpLen : 53.5
Train_AverageReturn : 37.3880615234375
Train_StdReturn : 19.58140754699707
Train_MaxReturn : 102.0
Train_MinReturn : 6.0
Train_AverageEpLen : 37.38805970149254
Actor Loss : -69.81861877441406
Baseline Loss : 454.1751342773438
Train_EnvstepsSoFar : 35039
TimeSinceStart : 3.7310729026794434
Done logging...



********** Iteration 7 ************

Collecting data for eval...
Eval_AverageReturn : 55.75
Eval_StdReturn : 19.376209259033203
Eval_MaxReturn : 100.0
Eval_MinReturn : 27.0
Eval_AverageEpLen : 55.75
Train_AverageReturn : 40.65853500366211
Train_StdReturn : 19.12637710571289
Train_MaxReturn : 118.0
Train_MinReturn : 11.0
Train_AverageEpLen : 40.65853658536585
Actor Loss : -70.36965942382812
Baseline Loss : 458.70717163085936
Train_EnvstepsSoFar : 40040
TimeSinceStart : 4.208085060119629
Done logging...



********** Iteration 8 ************

Collecting data for eval...
Eval_AverageReturn : 51.25
Eval_StdReturn : 27.04972267150879
Eval_MaxReturn : 106.0
Eval_MinReturn : 20.0
Eval_AverageEpLen : 51.25
Train_AverageReturn : 47.82857131958008
Train_StdReturn : 18.61564064025879
Train_MaxReturn : 101.0
Train_MinReturn : 12.0
Train_AverageEpLen : 47.82857142857143
Actor Loss : -143.36001586914062
Baseline Loss : 467.8124084472656
Train_EnvstepsSoFar : 45062
TimeSinceStart : 4.681300640106201
Done logging...



********** Iteration 9 ************

Collecting data for eval...
Eval_AverageReturn : 66.75
Eval_StdReturn : 38.081329345703125
Eval_MaxReturn : 157.0
Eval_MinReturn : 25.0
Eval_AverageEpLen : 66.75
Train_AverageReturn : 54.182796478271484
Train_StdReturn : 25.21731185913086
Train_MaxReturn : 131.0
Train_MinReturn : 14.0
Train_AverageEpLen : 54.18279569892473
Actor Loss : -121.81558227539062
Baseline Loss : 789.25810546875
Train_EnvstepsSoFar : 50101
TimeSinceStart : 5.166558504104614
Done logging...



********** Iteration 10 ************

Collecting data for eval...
Eval_AverageReturn : 73.16666412353516
Eval_StdReturn : 25.18211555480957
Eval_MaxReturn : 113.0
Eval_MinReturn : 47.0
Eval_AverageEpLen : 73.16666666666667
Train_AverageReturn : 61.91358184814453
Train_StdReturn : 30.014892578125
Train_MaxReturn : 169.0
Train_MinReturn : 19.0
Train_AverageEpLen : 61.91358024691358
Actor Loss : -84.61149597167969
Baseline Loss : 1154.051171875
Train_EnvstepsSoFar : 55116
TimeSinceStart : 5.65877366065979
Done logging...



********** Iteration 11 ************

Collecting data for eval...
Eval_AverageReturn : 70.33333587646484
Eval_StdReturn : 24.6959285736084
Eval_MaxReturn : 112.0
Eval_MinReturn : 46.0
Eval_AverageEpLen : 70.33333333333333
Train_AverageReturn : 63.924049377441406
Train_StdReturn : 31.12358856201172
Train_MaxReturn : 151.0
Train_MinReturn : 13.0
Train_AverageEpLen : 63.924050632911396
Actor Loss : -152.6099395751953
Baseline Loss : 1114.678466796875
Train_EnvstepsSoFar : 60166
TimeSinceStart : 6.148581027984619
Done logging...



********** Iteration 12 ************

Collecting data for eval...
Eval_AverageReturn : 76.85713958740234
Eval_StdReturn : 37.80184555053711
Eval_MaxReturn : 146.0
Eval_MinReturn : 31.0
Eval_AverageEpLen : 76.85714285714286
Train_AverageReturn : 67.46666717529297
Train_StdReturn : 29.683815002441406
Train_MaxReturn : 158.0
Train_MinReturn : 13.0
Train_AverageEpLen : 67.46666666666667
Actor Loss : -25.49081039428711
Baseline Loss : 1082.06630859375
Train_EnvstepsSoFar : 65226
TimeSinceStart : 6.639686584472656
Done logging...



********** Iteration 13 ************

Collecting data for eval...
Eval_AverageReturn : 76.42857360839844
Eval_StdReturn : 40.33380889892578
Eval_MaxReturn : 141.0
Eval_MinReturn : 34.0
Eval_AverageEpLen : 76.42857142857143
Train_AverageReturn : 75.47761535644531
Train_StdReturn : 38.066070556640625
Train_MaxReturn : 184.0
Train_MinReturn : 19.0
Train_AverageEpLen : 75.4776119402985
Actor Loss : 37.998313903808594
Baseline Loss : 1664.7824462890626
Train_EnvstepsSoFar : 70283
TimeSinceStart : 7.149762392044067
Done logging...



********** Iteration 14 ************

Collecting data for eval...
Eval_AverageReturn : 85.80000305175781
Eval_StdReturn : 35.39152526855469
Eval_MaxReturn : 129.0
Eval_MinReturn : 37.0
Eval_AverageEpLen : 85.8
Train_AverageReturn : 68.50685119628906
Train_StdReturn : 30.681806564331055
Train_MaxReturn : 179.0
Train_MinReturn : 18.0
Train_AverageEpLen : 68.5068493150685
Actor Loss : -105.88560485839844
Baseline Loss : 1040.5778564453126
Train_EnvstepsSoFar : 75284
TimeSinceStart : 7.622195243835449
Done logging...



********** Iteration 15 ************

Collecting data for eval...
Eval_AverageReturn : 102.75
Eval_StdReturn : 22.76373291015625
Eval_MaxReturn : 129.0
Eval_MinReturn : 67.0
Eval_AverageEpLen : 102.75
Train_AverageReturn : 83.2131118774414
Train_StdReturn : 39.033870697021484
Train_MaxReturn : 228.0
Train_MinReturn : 31.0
Train_AverageEpLen : 83.21311475409836
Actor Loss : -138.96775817871094
Baseline Loss : 1789.8975830078125
Train_EnvstepsSoFar : 80360
TimeSinceStart : 8.096518754959106
Done logging...



********** Iteration 16 ************

Collecting data for eval...
Eval_AverageReturn : 69.66666412353516
Eval_StdReturn : 35.382041931152344
Eval_MaxReturn : 145.0
Eval_MinReturn : 35.0
Eval_AverageEpLen : 69.66666666666667
Train_AverageReturn : 94.92453002929688
Train_StdReturn : 39.80606460571289
Train_MaxReturn : 207.0
Train_MinReturn : 30.0
Train_AverageEpLen : 94.9245283018868
Actor Loss : -102.73260498046875
Baseline Loss : 1935.4756591796875
Train_EnvstepsSoFar : 85391
TimeSinceStart : 8.552447080612183
Done logging...



********** Iteration 17 ************

Collecting data for eval...
Eval_AverageReturn : 99.4000015258789
Eval_StdReturn : 28.793054580688477
Eval_MaxReturn : 148.0
Eval_MinReturn : 60.0
Eval_AverageEpLen : 99.4
Train_AverageReturn : 89.30357360839844
Train_StdReturn : 51.213111877441406
Train_MaxReturn : 263.0
Train_MinReturn : 30.0
Train_AverageEpLen : 89.30357142857143
Actor Loss : 6.4006195068359375
Baseline Loss : 2805.607421875
Train_EnvstepsSoFar : 90392
TimeSinceStart : 9.023646831512451
Done logging...



********** Iteration 18 ************

Collecting data for eval...
Eval_AverageReturn : 87.80000305175781
Eval_StdReturn : 37.48813247680664
Eval_MaxReturn : 150.0
Eval_MinReturn : 41.0
Eval_AverageEpLen : 87.8
Train_AverageReturn : 85.49152374267578
Train_StdReturn : 34.56135559082031
Train_MaxReturn : 181.0
Train_MinReturn : 27.0
Train_AverageEpLen : 85.49152542372882
Actor Loss : -69.32459259033203
Baseline Loss : 1342.9986328125
Train_EnvstepsSoFar : 95436
TimeSinceStart : 9.506558895111084
Done logging...



********** Iteration 19 ************

Collecting data for eval...
Eval_AverageReturn : 76.28571319580078
Eval_StdReturn : 37.4993896484375
Eval_MaxReturn : 148.0
Eval_MinReturn : 29.0
Eval_AverageEpLen : 76.28571428571429
Train_AverageReturn : 96.26923370361328
Train_StdReturn : 45.498146057128906
Train_MaxReturn : 199.0
Train_MinReturn : 27.0
Train_AverageEpLen : 96.26923076923077
Actor Loss : -53.37336349487305
Baseline Loss : 2123.42783203125
Train_EnvstepsSoFar : 100442
TimeSinceStart : 9.982880353927612
Done logging...



********** Iteration 20 ************

Collecting data for eval...
Eval_AverageReturn : 108.4000015258789
Eval_StdReturn : 27.961400985717773
Eval_MaxReturn : 150.0
Eval_MinReturn : 79.0
Eval_AverageEpLen : 108.4
Train_AverageReturn : 113.24444580078125
Train_StdReturn : 42.480926513671875
Train_MaxReturn : 202.0
Train_MinReturn : 37.0
Train_AverageEpLen : 113.24444444444444
Actor Loss : -92.58419799804688
Baseline Loss : 2338.91240234375
Train_EnvstepsSoFar : 105538
TimeSinceStart : 10.465573787689209
Done logging...



********** Iteration 21 ************

Collecting data for eval...
Eval_AverageReturn : 134.0
Eval_StdReturn : 19.09624671936035
Eval_MaxReturn : 161.0
Eval_MinReturn : 120.0
Eval_AverageEpLen : 134.0
Train_AverageReturn : 110.5434799194336
Train_StdReturn : 57.85014343261719
Train_MaxReturn : 296.0
Train_MinReturn : 29.0
Train_AverageEpLen : 110.54347826086956
Actor Loss : -42.38711166381836
Baseline Loss : 3481.135888671875
Train_EnvstepsSoFar : 110623
TimeSinceStart : 10.939448595046997
Done logging...



********** Iteration 22 ************

Collecting data for eval...
Eval_AverageReturn : 96.0
Eval_StdReturn : 37.035118103027344
Eval_MaxReturn : 158.0
Eval_MinReturn : 57.0
Eval_AverageEpLen : 96.0
Train_AverageReturn : 125.07499694824219
Train_StdReturn : 52.60483932495117
Train_MaxReturn : 268.0
Train_MinReturn : 32.0
Train_AverageEpLen : 125.075
Actor Loss : -100.07272338867188
Baseline Loss : 3350.560595703125
Train_EnvstepsSoFar : 115626
TimeSinceStart : 11.41334581375122
Done logging...



********** Iteration 23 ************

Collecting data for eval...
Eval_AverageReturn : 106.5
Eval_StdReturn : 25.243810653686523
Eval_MaxReturn : 144.0
Eval_MinReturn : 73.0
Eval_AverageEpLen : 106.5
Train_AverageReturn : 100.18000030517578
Train_StdReturn : 38.611236572265625
Train_MaxReturn : 185.0
Train_MinReturn : 40.0
Train_AverageEpLen : 100.18
Actor Loss : -82.38821411132812
Baseline Loss : 1481.3109130859375
Train_EnvstepsSoFar : 120635
TimeSinceStart : 11.881415843963623
Done logging...



********** Iteration 24 ************

Collecting data for eval...
Eval_AverageReturn : 115.80000305175781
Eval_StdReturn : 68.96492004394531
Eval_MaxReturn : 210.0
Eval_MinReturn : 32.0
Eval_AverageEpLen : 115.8
Train_AverageReturn : 128.3249969482422
Train_StdReturn : 45.822696685791016
Train_MaxReturn : 242.0
Train_MinReturn : 40.0
Train_AverageEpLen : 128.325
Actor Loss : -13.65451431274414
Baseline Loss : 2779.61513671875
Train_EnvstepsSoFar : 125768
TimeSinceStart : 12.370012044906616
Done logging...



********** Iteration 25 ************

Collecting data for eval...
Eval_AverageReturn : 151.6666717529297
Eval_StdReturn : 43.099369049072266
Eval_MaxReturn : 212.0
Eval_MinReturn : 114.0
Eval_AverageEpLen : 151.66666666666666
Train_AverageReturn : 120.76190185546875
Train_StdReturn : 55.68654251098633
Train_MaxReturn : 312.0
Train_MinReturn : 41.0
Train_AverageEpLen : 120.76190476190476
Actor Loss : -55.863128662109375
Baseline Loss : 3364.7255859375
Train_EnvstepsSoFar : 130840
TimeSinceStart : 12.845325231552124
Done logging...



********** Iteration 26 ************

Collecting data for eval...
Eval_AverageReturn : 83.0
Eval_StdReturn : 16.087261199951172
Eval_MaxReturn : 113.0
Eval_MinReturn : 67.0
Eval_AverageEpLen : 83.0
Train_AverageReturn : 127.57499694824219
Train_StdReturn : 48.05303955078125
Train_MaxReturn : 218.0
Train_MinReturn : 46.0
Train_AverageEpLen : 127.575
Actor Loss : 35.990562438964844
Baseline Loss : 2594.944775390625
Train_EnvstepsSoFar : 135943
TimeSinceStart : 13.323429107666016
Done logging...



********** Iteration 27 ************

Collecting data for eval...
Eval_AverageReturn : 160.0
Eval_StdReturn : 73.82862854003906
Eval_MaxReturn : 264.0
Eval_MinReturn : 100.0
Eval_AverageEpLen : 160.0
Train_AverageReturn : 132.6923065185547
Train_StdReturn : 42.135406494140625
Train_MaxReturn : 252.0
Train_MinReturn : 52.0
Train_AverageEpLen : 132.69230769230768
Actor Loss : -78.15882110595703
Baseline Loss : 2557.25576171875
Train_EnvstepsSoFar : 141118
TimeSinceStart : 13.813486576080322
Done logging...



********** Iteration 28 ************

Collecting data for eval...
Eval_AverageReturn : 97.5999984741211
Eval_StdReturn : 19.158288955688477
Eval_MaxReturn : 119.0
Eval_MinReturn : 63.0
Eval_AverageEpLen : 97.6
Train_AverageReturn : 127.125
Train_StdReturn : 49.21289825439453
Train_MaxReturn : 268.0
Train_MinReturn : 49.0
Train_AverageEpLen : 127.125
Actor Loss : -67.79095458984375
Baseline Loss : 2806.865673828125
Train_EnvstepsSoFar : 146203
TimeSinceStart : 14.292009592056274
Done logging...



********** Iteration 29 ************

Collecting data for eval...
Eval_AverageReturn : 120.0
Eval_StdReturn : 10.173495292663574
Eval_MaxReturn : 132.0
Eval_MinReturn : 105.0
Eval_AverageEpLen : 120.0
Train_AverageReturn : 124.07317352294922
Train_StdReturn : 36.15103530883789
Train_MaxReturn : 210.0
Train_MinReturn : 44.0
Train_AverageEpLen : 124.07317073170732
Actor Loss : -32.75897216796875
Baseline Loss : 1823.800341796875
Train_EnvstepsSoFar : 151290
TimeSinceStart : 14.768146514892578
Done logging...



********** Iteration 30 ************

Collecting data for eval...
Eval_AverageReturn : 113.0
Eval_StdReturn : 55.04997634887695
Eval_MaxReturn : 149.0
Eval_MinReturn : 18.0
Eval_AverageEpLen : 113.0
Train_AverageReturn : 150.4705810546875
Train_StdReturn : 46.25837707519531
Train_MaxReturn : 278.0
Train_MinReturn : 59.0
Train_AverageEpLen : 150.47058823529412
Actor Loss : -56.37789535522461
Baseline Loss : 3088.03056640625
Train_EnvstepsSoFar : 156406
TimeSinceStart : 15.239405870437622
Done logging...



********** Iteration 31 ************

Collecting data for eval...
Eval_AverageReturn : 137.3333282470703
Eval_StdReturn : 9.672412872314453
Eval_MaxReturn : 151.0
Eval_MinReturn : 130.0
Eval_AverageEpLen : 137.33333333333334
Train_AverageReturn : 137.18919372558594
Train_StdReturn : 50.378482818603516
Train_MaxReturn : 323.0
Train_MinReturn : 78.0
Train_AverageEpLen : 137.1891891891892
Actor Loss : -89.10691833496094
Baseline Loss : 2973.478955078125
Train_EnvstepsSoFar : 161482
TimeSinceStart : 15.707402229309082
Done logging...



********** Iteration 32 ************

Collecting data for eval...
Eval_AverageReturn : 150.3333282470703
Eval_StdReturn : 8.653837203979492
Eval_MaxReturn : 160.0
Eval_MinReturn : 139.0
Eval_AverageEpLen : 150.33333333333334
Train_AverageReturn : 144.028564453125
Train_StdReturn : 45.78551483154297
Train_MaxReturn : 254.0
Train_MinReturn : 72.0
Train_AverageEpLen : 144.02857142857144
Actor Loss : -103.36105346679688
Baseline Loss : 2413.502099609375
Train_EnvstepsSoFar : 166523
TimeSinceStart : 16.180494785308838
Done logging...



********** Iteration 33 ************

Collecting data for eval...
Eval_AverageReturn : 136.25
Eval_StdReturn : 35.37919616699219
Eval_MaxReturn : 197.0
Eval_MinReturn : 110.0
Eval_AverageEpLen : 136.25
Train_AverageReturn : 151.757568359375
Train_StdReturn : 46.58067321777344
Train_MaxReturn : 296.0
Train_MinReturn : 32.0
Train_AverageEpLen : 151.75757575757575
Actor Loss : -39.93826675415039
Baseline Loss : 2937.396435546875
Train_EnvstepsSoFar : 171531
TimeSinceStart : 16.65316605567932
Done logging...



********** Iteration 34 ************

Collecting data for eval...
Eval_AverageReturn : 130.0
Eval_StdReturn : 16.20185089111328
Eval_MaxReturn : 152.0
Eval_MinReturn : 113.0
Eval_AverageEpLen : 130.0
Train_AverageReturn : 141.38888549804688
Train_StdReturn : 49.19026565551758
Train_MaxReturn : 330.0
Train_MinReturn : 86.0
Train_AverageEpLen : 141.38888888888889
Actor Loss : 4.724367141723633
Baseline Loss : 3232.31103515625
Train_EnvstepsSoFar : 176621
TimeSinceStart : 17.123242139816284
Done logging...



********** Iteration 35 ************

Collecting data for eval...
Eval_AverageReturn : 135.3333282470703
Eval_StdReturn : 28.075294494628906
Eval_MaxReturn : 175.0
Eval_MinReturn : 114.0
Eval_AverageEpLen : 135.33333333333334
Train_AverageReturn : 179.03448486328125
Train_StdReturn : 75.07811737060547
Train_MaxReturn : 457.0
Train_MinReturn : 75.0
Train_AverageEpLen : 179.0344827586207
Actor Loss : 37.027557373046875
Baseline Loss : 7449.0771484375
Train_EnvstepsSoFar : 181813
TimeSinceStart : 17.603124141693115
Done logging...



********** Iteration 36 ************

Collecting data for eval...
Eval_AverageReturn : 153.0
Eval_StdReturn : 17.048948287963867
Eval_MaxReturn : 167.0
Eval_MinReturn : 129.0
Eval_AverageEpLen : 153.0
Train_AverageReturn : 166.89999389648438
Train_StdReturn : 52.859153747558594
Train_MaxReturn : 291.0
Train_MinReturn : 106.0
Train_AverageEpLen : 166.9
Actor Loss : 31.499624252319336
Baseline Loss : 4028.8224609375
Train_EnvstepsSoFar : 186820
TimeSinceStart : 18.068361520767212
Done logging...



********** Iteration 37 ************

Collecting data for eval...
Eval_AverageReturn : 219.0
Eval_StdReturn : 28.0
Eval_MaxReturn : 247.0
Eval_MinReturn : 191.0
Eval_AverageEpLen : 219.0
Train_AverageReturn : 175.58621215820312
Train_StdReturn : 49.5103645324707
Train_MaxReturn : 364.0
Train_MinReturn : 118.0
Train_AverageEpLen : 175.58620689655172
Actor Loss : 36.062347412109375
Baseline Loss : 3829.365380859375
Train_EnvstepsSoFar : 191912
TimeSinceStart : 18.539122819900513
Done logging...



********** Iteration 38 ************

Collecting data for eval...
Eval_AverageReturn : 152.3333282470703
Eval_StdReturn : 22.42518424987793
Eval_MaxReturn : 184.0
Eval_MinReturn : 135.0
Eval_AverageEpLen : 152.33333333333334
Train_AverageReturn : 180.75
Train_StdReturn : 56.037376403808594
Train_MaxReturn : 342.0
Train_MinReturn : 47.0
Train_AverageEpLen : 180.75
Actor Loss : -129.86941528320312
Baseline Loss : 4104.9646484375
Train_EnvstepsSoFar : 196973
TimeSinceStart : 19.007290363311768
Done logging...



********** Iteration 39 ************

Collecting data for eval...
Eval_AverageReturn : 145.3333282470703
Eval_StdReturn : 16.57977294921875
Eval_MaxReturn : 159.0
Eval_MinReturn : 122.0
Eval_AverageEpLen : 145.33333333333334
Train_AverageReturn : 199.38461303710938
Train_StdReturn : 75.06001281738281
Train_MaxReturn : 393.0
Train_MinReturn : 65.0
Train_AverageEpLen : 199.3846153846154
Actor Loss : -32.93596649169922
Baseline Loss : 6933.22939453125
Train_EnvstepsSoFar : 202157
TimeSinceStart : 19.48576068878174
Done logging...



********** Iteration 40 ************

Collecting data for eval...
Eval_AverageReturn : 181.0
Eval_StdReturn : 35.33647537231445
Eval_MaxReturn : 214.0
Eval_MinReturn : 132.0
Eval_AverageEpLen : 181.0
Train_AverageReturn : 212.4166717529297
Train_StdReturn : 75.21298217773438
Train_MaxReturn : 396.0
Train_MinReturn : 123.0
Train_AverageEpLen : 212.41666666666666
Actor Loss : -9.527179718017578
Baseline Loss : 7956.65966796875
Train_EnvstepsSoFar : 207255
TimeSinceStart : 19.969608068466187
Done logging...



********** Iteration 41 ************

Collecting data for eval...
Eval_AverageReturn : 192.3333282470703
Eval_StdReturn : 9.53356647491455
Eval_MaxReturn : 205.0
Eval_MinReturn : 182.0
Eval_AverageEpLen : 192.33333333333334
Train_AverageReturn : 181.67857360839844
Train_StdReturn : 56.22280502319336
Train_MaxReturn : 293.0
Train_MinReturn : 62.0
Train_AverageEpLen : 181.67857142857142
Actor Loss : -71.96116638183594
Baseline Loss : 4147.255078125
Train_EnvstepsSoFar : 212342
TimeSinceStart : 20.451836347579956
Done logging...



********** Iteration 42 ************

Collecting data for eval...
Eval_AverageReturn : 344.5
Eval_StdReturn : 22.5
Eval_MaxReturn : 367.0
Eval_MinReturn : 322.0
Eval_AverageEpLen : 344.5
Train_AverageReturn : 208.9583282470703
Train_StdReturn : 73.01225280761719
Train_MaxReturn : 379.0
Train_MinReturn : 121.0
Train_AverageEpLen : 208.95833333333334
Actor Loss : -35.87643814086914
Baseline Loss : 7421.7486328125
Train_EnvstepsSoFar : 217357
TimeSinceStart : 20.939360857009888
Done logging...



********** Iteration 43 ************

Collecting data for eval...
Eval_AverageReturn : 292.0
Eval_StdReturn : 106.0
Eval_MaxReturn : 398.0
Eval_MinReturn : 186.0
Eval_AverageEpLen : 292.0
Train_AverageReturn : 253.64999389648438
Train_StdReturn : 77.79348754882812
Train_MaxReturn : 390.0
Train_MinReturn : 79.0
Train_AverageEpLen : 253.65
Actor Loss : -90.33595275878906
Baseline Loss : 9852.62578125
Train_EnvstepsSoFar : 222430
TimeSinceStart : 21.421937942504883
Done logging...



********** Iteration 44 ************

Collecting data for eval...
Eval_AverageReturn : 217.0
Eval_StdReturn : 35.0
Eval_MaxReturn : 252.0
Eval_MinReturn : 182.0
Eval_AverageEpLen : 217.0
Train_AverageReturn : 270.47369384765625
Train_StdReturn : 86.90791320800781
Train_MaxReturn : 460.0
Train_MinReturn : 76.0
Train_AverageEpLen : 270.4736842105263
Actor Loss : -61.788238525390625
Baseline Loss : 11909.3125
Train_EnvstepsSoFar : 227569
TimeSinceStart : 21.903248071670532
Done logging...



********** Iteration 45 ************

Collecting data for eval...
Eval_AverageReturn : 428.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 428.0
Eval_MinReturn : 428.0
Eval_AverageEpLen : 428.0
Train_AverageReturn : 284.0555419921875
Train_StdReturn : 92.0884017944336
Train_MaxReturn : 442.0
Train_MinReturn : 114.0
Train_AverageEpLen : 284.05555555555554
Actor Loss : -37.742942810058594
Baseline Loss : 13584.41796875
Train_EnvstepsSoFar : 232682
TimeSinceStart : 22.375473976135254
Done logging...



********** Iteration 46 ************

Collecting data for eval...
Eval_AverageReturn : 292.5
Eval_StdReturn : 9.5
Eval_MaxReturn : 302.0
Eval_MinReturn : 283.0
Eval_AverageEpLen : 292.5
Train_AverageReturn : 310.3529357910156
Train_StdReturn : 144.20611572265625
Train_MaxReturn : 655.0
Train_MinReturn : 56.0
Train_AverageEpLen : 310.3529411764706
Actor Loss : -5.328213691711426
Baseline Loss : 25466.293359375
Train_EnvstepsSoFar : 237958
TimeSinceStart : 22.875247478485107
Done logging...



********** Iteration 47 ************

Collecting data for eval...
Eval_AverageReturn : 596.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 596.0
Eval_MinReturn : 596.0
Eval_AverageEpLen : 596.0
Train_AverageReturn : 331.8125
Train_StdReturn : 85.36482238769531
Train_MaxReturn : 480.0
Train_MinReturn : 173.0
Train_AverageEpLen : 331.8125
Actor Loss : -25.048093795776367
Baseline Loss : 17451.428125
Train_EnvstepsSoFar : 243267
TimeSinceStart : 23.381396532058716
Done logging...



********** Iteration 48 ************

Collecting data for eval...
Eval_AverageReturn : 513.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 513.0
Eval_MinReturn : 513.0
Eval_AverageEpLen : 513.0
Train_AverageReturn : 317.4375
Train_StdReturn : 131.8194580078125
Train_MaxReturn : 530.0
Train_MinReturn : 51.0
Train_AverageEpLen : 317.4375
Actor Loss : 14.160711288452148
Baseline Loss : 20665.80390625
Train_EnvstepsSoFar : 248346
TimeSinceStart : 23.856517791748047
Done logging...



********** Iteration 49 ************

Collecting data for eval...
Eval_AverageReturn : 707.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 707.0
Eval_MinReturn : 707.0
Eval_AverageEpLen : 707.0
Train_AverageReturn : 426.1666564941406
Train_StdReturn : 285.85394287109375
Train_MaxReturn : 972.0
Train_MinReturn : 89.0
Train_AverageEpLen : 426.1666666666667
Actor Loss : -21.6538143157959
Baseline Loss : 96396.3828125
Train_EnvstepsSoFar : 253460
TimeSinceStart : 24.3455069065094
Done logging...



********** Iteration 50 ************

Collecting data for eval...
Eval_AverageReturn : 804.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 804.0
Eval_MinReturn : 804.0
Eval_AverageEpLen : 804.0
Train_AverageReturn : 424.3333435058594
Train_StdReturn : 214.60325622558594
Train_MaxReturn : 876.0
Train_MinReturn : 102.0
Train_AverageEpLen : 424.3333333333333
Actor Loss : -69.01139831542969
Baseline Loss : 57485.11484375
Train_EnvstepsSoFar : 258552
TimeSinceStart : 24.845131874084473
Done logging...



********** Iteration 51 ************

Collecting data for eval...
Eval_AverageReturn : 308.0
Eval_StdReturn : 183.0
Eval_MaxReturn : 491.0
Eval_MinReturn : 125.0
Eval_AverageEpLen : 308.0
Train_AverageReturn : 380.4285583496094
Train_StdReturn : 286.81494140625
Train_MaxReturn : 1000.0
Train_MinReturn : 86.0
Train_AverageEpLen : 380.42857142857144
Actor Loss : -118.26490783691406
Baseline Loss : 93151.5171875
Train_EnvstepsSoFar : 263878
TimeSinceStart : 25.3531653881073
Done logging...



********** Iteration 52 ************

Collecting data for eval...
Eval_AverageReturn : 509.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 509.0
Eval_MinReturn : 509.0
Eval_AverageEpLen : 509.0
Train_AverageReturn : 702.0
Train_StdReturn : 314.3465576171875
Train_MaxReturn : 1000.0
Train_MinReturn : 202.0
Train_AverageEpLen : 702.0
Actor Loss : 62.82014083862305
Baseline Loss : 164646.340625
Train_EnvstepsSoFar : 269494
TimeSinceStart : 25.88045310974121
Done logging...



********** Iteration 53 ************

Collecting data for eval...
Eval_AverageReturn : 707.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 707.0
Eval_MinReturn : 707.0
Eval_AverageEpLen : 707.0
Train_AverageReturn : 321.0625
Train_StdReturn : 251.65811157226562
Train_MaxReturn : 1000.0
Train_MinReturn : 108.0
Train_AverageEpLen : 321.0625
Actor Loss : -18.954681396484375
Baseline Loss : 73571.6890625
Train_EnvstepsSoFar : 274631
TimeSinceStart : 26.378051280975342
Done logging...



********** Iteration 54 ************

Collecting data for eval...
Eval_AverageReturn : 757.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 757.0
Eval_MinReturn : 757.0
Eval_AverageEpLen : 757.0
Train_AverageReturn : 316.1764831542969
Train_StdReturn : 141.89276123046875
Train_MaxReturn : 622.0
Train_MinReturn : 114.0
Train_AverageEpLen : 316.1764705882353
Actor Loss : -17.6332950592041
Baseline Loss : 22174.84296875
Train_EnvstepsSoFar : 280006
TimeSinceStart : 26.899633169174194
Done logging...



********** Iteration 55 ************

Collecting data for eval...
Eval_AverageReturn : 630.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 630.0
Eval_MinReturn : 630.0
Eval_AverageEpLen : 630.0
Train_AverageReturn : 392.30767822265625
Train_StdReturn : 275.99981689453125
Train_MaxReturn : 802.0
Train_MinReturn : 68.0
Train_AverageEpLen : 392.3076923076923
Actor Loss : -99.71269226074219
Baseline Loss : 70348.415625
Train_EnvstepsSoFar : 285106
TimeSinceStart : 27.385374784469604
Done logging...



********** Iteration 56 ************

Collecting data for eval...
Eval_AverageReturn : 658.0
Eval_StdReturn : 342.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 316.0
Eval_AverageEpLen : 658.0
Train_AverageReturn : 440.6666564941406
Train_StdReturn : 242.56040954589844
Train_MaxReturn : 1000.0
Train_MinReturn : 59.0
Train_AverageEpLen : 440.6666666666667
Actor Loss : 41.69055938720703
Baseline Loss : 67194.0015625
Train_EnvstepsSoFar : 290394
TimeSinceStart : 27.95304799079895
Done logging...



********** Iteration 57 ************

Collecting data for eval...
Eval_AverageReturn : 441.0
Eval_StdReturn : 345.0
Eval_MaxReturn : 786.0
Eval_MinReturn : 96.0
Eval_AverageEpLen : 441.0
Train_AverageReturn : 422.0833435058594
Train_StdReturn : 280.2544860839844
Train_MaxReturn : 927.0
Train_MinReturn : 66.0
Train_AverageEpLen : 422.0833333333333
Actor Loss : -89.50463104248047
Baseline Loss : 76989.259375
Train_EnvstepsSoFar : 295459
TimeSinceStart : 28.460597038269043
Done logging...



********** Iteration 58 ************

Collecting data for eval...
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 648.5
Train_StdReturn : 288.6949157714844
Train_MaxReturn : 1000.0
Train_MinReturn : 235.0
Train_AverageEpLen : 648.5
Actor Loss : -80.14955139160156
Baseline Loss : 128917.6015625
Train_EnvstepsSoFar : 300647
TimeSinceStart : 28.990009784698486
Done logging...



********** Iteration 59 ************

Collecting data for eval...
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 854.6666870117188
Train_StdReturn : 183.83929443359375
Train_MaxReturn : 1000.0
Train_MinReturn : 514.0
Train_AverageEpLen : 854.6666666666666
Actor Loss : -35.41865921020508
Baseline Loss : 162288.234375
Train_EnvstepsSoFar : 305775
TimeSinceStart : 29.51650357246399
Done logging...



********** Iteration 60 ************

Collecting data for eval...
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 594.5555419921875
Train_StdReturn : 318.29620361328125
Train_MaxReturn : 1000.0
Train_MinReturn : 200.0
Train_AverageEpLen : 594.5555555555555
Actor Loss : -155.05072021484375
Baseline Loss : 127709.484375
Train_EnvstepsSoFar : 311126
TimeSinceStart : 30.070313930511475
Done logging...



********** Iteration 61 ************

Collecting data for eval...
Eval_AverageReturn : 382.0
Eval_StdReturn : 32.0
Eval_MaxReturn : 414.0
Eval_MinReturn : 350.0
Eval_AverageEpLen : 382.0
Train_AverageReturn : 769.5714111328125
Train_StdReturn : 267.5133361816406
Train_MaxReturn : 1000.0
Train_MinReturn : 404.0
Train_AverageEpLen : 769.5714285714286
Actor Loss : 39.7305908203125
Baseline Loss : 153998.10625
Train_EnvstepsSoFar : 316513
TimeSinceStart : 30.60975933074951
Done logging...



********** Iteration 62 ************

Collecting data for eval...
Eval_AverageReturn : 578.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 578.0
Eval_MinReturn : 578.0
Eval_AverageEpLen : 578.0
Train_AverageReturn : 723.25
Train_StdReturn : 325.9956970214844
Train_MaxReturn : 1000.0
Train_MinReturn : 201.0
Train_AverageEpLen : 723.25
Actor Loss : -59.62445831298828
Baseline Loss : 154206.64375
Train_EnvstepsSoFar : 322299
TimeSinceStart : 31.145899772644043
Done logging...



********** Iteration 63 ************

Collecting data for eval...
Eval_AverageReturn : 603.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 603.0
Eval_MinReturn : 603.0
Eval_AverageEpLen : 603.0
Train_AverageReturn : 669.75
Train_StdReturn : 319.2541198730469
Train_MaxReturn : 1000.0
Train_MinReturn : 150.0
Train_AverageEpLen : 669.75
Actor Loss : -28.972259521484375
Baseline Loss : 131371.3328125
Train_EnvstepsSoFar : 327657
TimeSinceStart : 31.647981643676758
Done logging...



********** Iteration 64 ************

Collecting data for eval...
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 739.8571166992188
Train_StdReturn : 168.2349090576172
Train_MaxReturn : 934.0
Train_MinReturn : 433.0
Train_AverageEpLen : 739.8571428571429
Actor Loss : 0.8590764999389648
Baseline Loss : 105207.4265625
Train_EnvstepsSoFar : 332836
TimeSinceStart : 32.17805218696594
Done logging...



********** Iteration 65 ************

Collecting data for eval...
Eval_AverageReturn : 654.0
Eval_StdReturn : 346.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 308.0
Eval_AverageEpLen : 654.0
Train_AverageReturn : 885.3333129882812
Train_StdReturn : 204.9224853515625
Train_MaxReturn : 1000.0
Train_MinReturn : 439.0
Train_AverageEpLen : 885.3333333333334
Actor Loss : 25.07096290588379
Baseline Loss : 165692.875
Train_EnvstepsSoFar : 338148
TimeSinceStart : 32.73244261741638
Done logging...



********** Iteration 66 ************

Collecting data for eval...
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : -22.351032257080078
Baseline Loss : 186942.840625
Train_EnvstepsSoFar : 343148
TimeSinceStart : 33.247740745544434
Done logging...



********** Iteration 67 ************

Collecting data for eval...
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : -9.43556022644043
Baseline Loss : 184617.075
Train_EnvstepsSoFar : 348148
TimeSinceStart : 33.75577354431152
Done logging...



********** Iteration 68 ************

Collecting data for eval...
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : -39.18463897705078
Baseline Loss : 182312.11875
Train_EnvstepsSoFar : 353148
TimeSinceStart : 34.2710063457489
Done logging...



********** Iteration 69 ************

Collecting data for eval...
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : -23.9429988861084
Baseline Loss : 180070.815625
Train_EnvstepsSoFar : 358148
TimeSinceStart : 34.77725267410278
Done logging...



********** Iteration 70 ************

Collecting data for eval...
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : -35.146183013916016
Baseline Loss : 177910.81875
Train_EnvstepsSoFar : 363148
TimeSinceStart : 35.28482174873352
Done logging...



********** Iteration 71 ************

Collecting data for eval...
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : -84.48621368408203
Baseline Loss : 175837.109375
Train_EnvstepsSoFar : 368148
TimeSinceStart : 35.79706358909607
Done logging...



********** Iteration 72 ************

Collecting data for eval...
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : 109.17105102539062
Baseline Loss : 173848.384375
Train_EnvstepsSoFar : 373148
TimeSinceStart : 36.303303480148315
Done logging...



********** Iteration 73 ************

Collecting data for eval...
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 933.6666870117188
Train_StdReturn : 148.32583618164062
Train_MaxReturn : 1000.0
Train_MinReturn : 602.0
Train_AverageEpLen : 933.6666666666666
Actor Loss : 53.416683197021484
Baseline Loss : 157763.065625
Train_EnvstepsSoFar : 378750
TimeSinceStart : 36.86505317687988
Done logging...



********** Iteration 74 ************

Collecting data for eval...
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : -12.940862655639648
Baseline Loss : 170152.28125
Train_EnvstepsSoFar : 383750
TimeSinceStart : 37.37182879447937
Done logging...



********** Iteration 75 ************

Collecting data for eval...
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : -32.9090576171875
Baseline Loss : 168414.015625
Train_EnvstepsSoFar : 388750
TimeSinceStart : 37.89581060409546
Done logging...



********** Iteration 76 ************

Collecting data for eval...
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : -31.543907165527344
Baseline Loss : 166727.39375
Train_EnvstepsSoFar : 393750
TimeSinceStart : 38.40799283981323
Done logging...



********** Iteration 77 ************

Collecting data for eval...
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : -78.076904296875
Baseline Loss : 165093.340625
Train_EnvstepsSoFar : 398750
TimeSinceStart : 38.90859889984131
Done logging...



********** Iteration 78 ************

Collecting data for eval...
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : -8.466066360473633
Baseline Loss : 163510.728125
Train_EnvstepsSoFar : 403750
TimeSinceStart : 39.4183554649353
Done logging...



********** Iteration 79 ************

Collecting data for eval...
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : 24.8216609954834
Baseline Loss : 161977.446875
Train_EnvstepsSoFar : 408750
TimeSinceStart : 39.93539476394653
Done logging...



********** Iteration 80 ************

Collecting data for eval...
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : -14.79529094696045
Baseline Loss : 160491.025
Train_EnvstepsSoFar : 413750
TimeSinceStart : 40.44607090950012
Done logging...



********** Iteration 81 ************

Collecting data for eval...
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : -77.57137298583984
Baseline Loss : 159048.85
Train_EnvstepsSoFar : 418750
TimeSinceStart : 40.9568874835968
Done logging...



********** Iteration 82 ************

Collecting data for eval...
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : 26.867042541503906
Baseline Loss : 157648.421875
Train_EnvstepsSoFar : 423750
TimeSinceStart : 41.465579986572266
Done logging...



********** Iteration 83 ************

Collecting data for eval...
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : -41.71857833862305
Baseline Loss : 156287.35625
Train_EnvstepsSoFar : 428750
TimeSinceStart : 41.9782817363739
Done logging...



********** Iteration 84 ************

Collecting data for eval...
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : -68.60106658935547
Baseline Loss : 154963.4375
Train_EnvstepsSoFar : 433750
TimeSinceStart : 42.49510860443115
Done logging...



********** Iteration 85 ************

Collecting data for eval...
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : 64.84336853027344
Baseline Loss : 153675.3625
Train_EnvstepsSoFar : 438750
TimeSinceStart : 43.01129913330078
Done logging...



********** Iteration 86 ************

Collecting data for eval...
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 858.0
Train_StdReturn : 306.0413818359375
Train_MaxReturn : 1000.0
Train_MinReturn : 174.0
Train_AverageEpLen : 858.0
Actor Loss : -6.297008514404297
Baseline Loss : 146049.6625
Train_EnvstepsSoFar : 443898
TimeSinceStart : 43.53875374794006
Done logging...



********** Iteration 87 ************

Collecting data for eval...
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : -32.82453918457031
Baseline Loss : 151223.134375
Train_EnvstepsSoFar : 448898
TimeSinceStart : 44.05605697631836
Done logging...



********** Iteration 88 ************

Collecting data for eval...
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 463.81817626953125
Train_StdReturn : 286.803955078125
Train_MaxReturn : 1000.0
Train_MinReturn : 122.0
Train_AverageEpLen : 463.8181818181818
Actor Loss : 27.819869995117188
Baseline Loss : 60771.81640625
Train_EnvstepsSoFar : 454000
TimeSinceStart : 44.57673740386963
Done logging...



********** Iteration 89 ************

Collecting data for eval...
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 667.375
Train_StdReturn : 372.2021789550781
Train_MaxReturn : 1000.0
Train_MinReturn : 86.0
Train_AverageEpLen : 667.375
Actor Loss : -46.36948776245117
Baseline Loss : 120228.278125
Train_EnvstepsSoFar : 459339
TimeSinceStart : 45.118900299072266
Done logging...



********** Iteration 90 ************

Collecting data for eval...
Eval_AverageReturn : 466.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 466.0
Eval_MinReturn : 466.0
Eval_AverageEpLen : 466.0
Train_AverageReturn : 914.5
Train_StdReturn : 191.18380737304688
Train_MaxReturn : 1000.0
Train_MinReturn : 487.0
Train_AverageEpLen : 914.5
Actor Loss : 47.353519439697266
Baseline Loss : 136940.80625
Train_EnvstepsSoFar : 464826
TimeSinceStart : 45.63025140762329
Done logging...



********** Iteration 91 ************

Collecting data for eval...
Eval_AverageReturn : 599.0
Eval_StdReturn : 401.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 198.0
Eval_AverageEpLen : 599.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : -50.78704833984375
Baseline Loss : 147426.7375
Train_EnvstepsSoFar : 469826
TimeSinceStart : 46.170616149902344
Done logging...



********** Iteration 92 ************

Collecting data for eval...
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : 17.086807250976562
Baseline Loss : 146439.440625
Train_EnvstepsSoFar : 474826
TimeSinceStart : 46.68676686286926
Done logging...



********** Iteration 93 ************

Collecting data for eval...
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : 16.289039611816406
Baseline Loss : 145418.853125
Train_EnvstepsSoFar : 479826
TimeSinceStart : 47.19723582267761
Done logging...



********** Iteration 94 ************

Collecting data for eval...
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : 37.149513244628906
Baseline Loss : 144388.4875
Train_EnvstepsSoFar : 484826
TimeSinceStart : 47.709577322006226
Done logging...



********** Iteration 95 ************

Collecting data for eval...
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : -50.051292419433594
Baseline Loss : 143361.509375
Train_EnvstepsSoFar : 489826
TimeSinceStart : 48.226216077804565
Done logging...



********** Iteration 96 ************

Collecting data for eval...
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : -18.68785285949707
Baseline Loss : 142345.3625
Train_EnvstepsSoFar : 494826
TimeSinceStart : 48.73666596412659
Done logging...



********** Iteration 97 ************

Collecting data for eval...
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : -37.726646423339844
Baseline Loss : 141344.115625
Train_EnvstepsSoFar : 499826
TimeSinceStart : 49.24741172790527
Done logging...



********** Iteration 98 ************

Collecting data for eval...
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : -6.901910781860352
Baseline Loss : 140359.809375
Train_EnvstepsSoFar : 504826
TimeSinceStart : 49.758378744125366
Done logging...



********** Iteration 99 ************

Collecting data for eval...
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : -9.264567375183105
Baseline Loss : 139393.4125
Train_EnvstepsSoFar : 509826
TimeSinceStart : 50.27212929725647
Done logging...


